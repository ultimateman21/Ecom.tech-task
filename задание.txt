Тестовое задание 
В этом тестовом задании мы предлагаем вам реализовать простой ETL для расчета 
аналитического запроса над несколькими связанными источниками и оформить его в виде 
прототипа приложения, готового к запуску и тестированию c использованием 
контейнеризации.

Контекст 
Пользователи (user) оформляют заказы (order) в некоторых магазинах (store). 
Упрощенная модель данных для этого процесса выглядит так(pic задание)

Задача: необходимо для каждого города (store.city) определить 
топ-3 магазинов по общей cумме заказов (order.amount), сделанных 
пользователями с датой регистрации в 2025 году (user.created_at)

В результате мы ожидаем получить такую структуру, 
где city - название города (store.city), 
store_name - название магазина (store.name), а 
target_amount - целевая сумма:

Инфраструктура и технологии 
• Для чтения, записи и трансформации данных вы можете использовать Apache Spark 
(предпочтительно) + Python, Scala или Java
Или же задействовать для вашего приложения только Python (возможно с привлечением 
библиотек Pandas или Polars)

• Приложение должно работать с S3-совместимым хранилищем (например, Minio)
Входные данные ожидаются в виде Parquet-файлов (отдельных для store / order / user). 
Результат также записываем в Parquet
Для тестирования вашего приложения вы можете использовать сформированные 
заранее датасеты или написать скрипт для их генерации.

• Приложение разворачивается в Docker, а ваш проект - содержит скрипт docker-
compose, который запускает и оркестрирует все необходимые вашему приложению 
контейнеры, в т.ч. контейнер с S3-совместимым хранилищем